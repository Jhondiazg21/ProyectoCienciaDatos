# Predictor de Riesgo de Insuficiencia Card√≠aca

Proyecto de ciencia de datos para la predicci√≥n de eventos fatales en pacientes con insuficiencia card√≠aca mediante modelos de machine learning. Este proyecto incluye un an√°lisis exploratorio completo, preprocesamiento de datos, modelado predictivo y una aplicaci√≥n web interactiva con Streamlit.

## Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Caracter√≠sticas](#-caracter√≠sticas)
- [Dataset](#-dataset)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos](#-requisitos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Modelos Implementados](#-modelos-implementados)
- [Resultados](#-resultados)

## Descripci√≥n del Proyecto

Este proyecto se enfoca en desarrollar modelos predictivos para identificar pacientes con mayor riesgo de eventos fatales por insuficiencia card√≠aca. Utiliza t√©cnicas de machine learning para analizar variables cl√≠nicas y generar predicciones precisas que pueden ayudar en la toma de decisiones m√©dicas. 

**Destacado**: El proyecto trabaja con un enfoque dual, utilizando tanto datos originales limpios como datos sint√©ticos con ruido para replicar desaf√≠os reales en la transformaci√≥n y limpieza de datos.

### Objetivos

- Realizar un an√°lisis exploratorio exhaustivo de los datos cl√≠nicos
- Probar el preprocesamiento tanto con datos originales limpios como con datos sint√©ticos con ruido
- Crear pipelines robustos de limpieza y transformaci√≥n de datos
- Comparar el rendimiento de m√∫ltiples algoritmos de clasificaci√≥n
- Desplegar un modelo predictivo en una aplicaci√≥n web interactiva

## Caracter√≠sticas

- **Enfoque dual con datos**: Trabajo con dataset original limpio y datos sint√©ticos modificados con ruido
- **EDA completo** con visualizaciones interactivas (Matplotlib, Seaborn, Plotly)
- **Generaci√≥n de datos sint√©ticos** usando Gaussian Mixture Models (GMM)
- **Preprocesamiento robusto** que maneja:
  - Valores faltantes
  - Inconsistencias de tipo de datos
  - Valores extremos y at√≠picos
  - Errores comunes en datos reales
- **Modelado con scikit-learn**: Regresi√≥n Log√≠stica y Random Forest
- **Aplicaci√≥n web** con Streamlit para predicciones interactivas
- **An√°lisis de importancia de variables** y m√©tricas de evaluaci√≥n

## Dataset

### Fuente
- **Nombre**: Heart Failure Clinical Records Dataset
- **Origen**: [Kaggle](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction) / [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records)
- **Licencia**: Apache 2.0
- **Tipo**: Clasificaci√≥n binaria

### Variables

El dataset contiene informaci√≥n cl√≠nica de pacientes con insuficiencia card√≠aca:

| Variable | Tipo | Descripci√≥n |
|----------|------|-------------|
| `age` | Num√©rico | Edad del paciente en a√±os |
| `anaemia` | Binario | Disminuci√≥n de gl√≥bulos rojos o hemoglobina (1 = s√≠, 0 = no) |
| `creatinine_phosphokinase` | Num√©rico | Nivel de la enzima CPK en sangre (mcg/L) |
| `diabetes` | Binario | Indica si el paciente tiene diabetes (1 = s√≠, 0 = no) |
| `ejection_fraction` | Num√©rico | Porcentaje de sangre expulsada por el coraz√≥n en cada contracci√≥n |
| `high_blood_pressure` | Binario | Indica si el paciente tiene hipertensi√≥n (1 = s√≠, 0 = no) |
| `platelets` | Num√©rico | N√∫mero de plaquetas en sangre (kiloplaquetas/mL) |
| `serum_creatinine` | Num√©rico | Nivel de creatinina en sangre (mg/dL) |
| `serum_sodium` | Num√©rico | Nivel de sodio en sangre (mEq/L) |
| `sex` | Binario | Sexo del paciente (1 = masculino, 0 = femenino) |
| `smoking` | Binario | Indica si el paciente fuma (1 = s√≠, 0 = no) |
| `time` | Num√©rico | Tiempo de seguimiento en d√≠as |
| `DEATH_EVENT` | Binario | Variable objetivo (0 = sobrevivi√≥, 1 = falleci√≥) |

### Enfoque de Trabajo con Datos

Este proyecto implementa un enfoque dual para el tratamiento de datos, permitiendo trabajar tanto con informaci√≥n original como con datos sint√©ticos modificados:

#### 1. Dataset Original
- **Archivo**: `heart_failure_clinical_records_dataset.csv`
- **Registros**: 299 pacientes
- **Calidad**: Datos limpios y consistentes de Kaggle/UCI
- **Uso**: Baseline y an√°lisis exploratorio inicial

#### 2. Datos Sint√©ticos con Ruido
- **Registros**: Ampliaci√≥n a 2,299 (299 originales + 2,000 sint√©ticos)
- **T√©cnica**: Gaussian Mixture Models (GMM) preservando correlaciones
- **Modificaciones introducidas para mayor realismo**:
  - Valores faltantes aleatorios (5-15% por columna)
  - Cambios de tipo de dato (num√©ricos a texto con unidades)
  - Inconsistencias en codificaciones (ej: 'YES', 'NO', 'N/A' para booleanos)
  - Valores at√≠picos (valores negativos o fuera de rango)
  - Conversiones de formato (sexo como 'MALE'/'FEMALE' en vez de binario)
  
#### ¬øPor qu√© datos sint√©ticos modificados?
Este enfoque retador replica situaciones reales donde los datos llegan "sucios" desde diferentes fuentes, exigiendo robustez en:
- **Limpieza y transformaci√≥n**: Manejo de m√∫ltiples formatos e inconsistencias
- **Imputaci√≥n inteligente**: Decisi√≥n sobre qu√© imputar y qu√© eliminar
- **Validaci√≥n de pipelines**: Asegurar que el proceso sea reproducible y confiable

## üìÅ Estructura del Proyecto

```
ProyectoCienciaDatos/
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Datos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # Datos originales
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ heart_failure_clinical_records_dataset.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/                 # Datos procesados
‚îÇ       ‚îú‚îÄ‚îÄ heart_failure_augmented.csv
‚îÇ       ‚îî‚îÄ‚îÄ heart_failure_clinical_records_extended_cleaned.csv
‚îÇ
‚îú‚îÄ‚îÄ models/                        # Modelos entrenados
‚îÇ   ‚îî‚îÄ‚îÄ trained/
‚îÇ       ‚îú‚îÄ‚îÄ heart_failure_clinical_records-logistic_regression.joblib
‚îÇ       ‚îî‚îÄ‚îÄ heart_failure_clinical_records-random-forest.joblib
‚îÇ
‚îú‚îÄ‚îÄ src/                           # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ data_exploration/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ eda.ipynb              # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ notebook/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Notebook_dataset_base.ipynb
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Notebook_dataset_sintetico.ipynb
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Notebook_dataset_sintetico_transformados.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing_modeling/
‚îÇ       ‚îî‚îÄ‚îÄ preprocessing_and_models.ipynb  # Preprocesamiento y modelado
‚îÇ
‚îú‚îÄ‚îÄ reports/                       # Reportes y aplicaciones
‚îÇ   ‚îî‚îÄ‚îÄ app.py                     # Aplicaci√≥n Streamlit
‚îÇ
‚îú‚îÄ‚îÄ Notebook/                      # Carpeta adicional de notebooks
‚îÇ
‚îú‚îÄ‚îÄ .venv/                         # Entorno virtual (no versionar)
‚îú‚îÄ‚îÄ pyproject.toml                 # Configuraci√≥n del proyecto y dependencias
‚îú‚îÄ‚îÄ uv.lock                        # Lock file de dependencias
‚îú‚îÄ‚îÄ .python-version                # Versi√≥n de Python
‚îî‚îÄ‚îÄ README.md                      # Este archivo

```

## Requisitos

- **Python**: >= 3.13
- **Gestor de paquetes**: uv (recomendado) o pip

### Dependencias Principales

- `pandas`: Manipulaci√≥n y an√°lisis de datos
- `numpy`: Operaciones num√©ricas
- `scikit-learn`: Machine learning
- `matplotlib`: Visualizaci√≥n b√°sica
- `seaborn`: Visualizaci√≥n estad√≠stica
- `plotly`: Visualizaciones interactivas
- `streamlit`: Aplicaci√≥n web
- `autoviz`: Visualizaci√≥n automatizada

Ver todas las dependencias en `pyproject.toml`.

## Instalaci√≥n

### Opci√≥n 1: Usando uv (Recomendado)

```bash
# Clonar el repositorio
git clone <url-del-repositorio>
cd ProyectoCienciaDatos

# Instalar uv si no est√° instalado
curl -LsSf https://astral.sh/uv/install.sh | sh  # Linux/Mac
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"  # Windows
# o descargar desde https://github.com/astral-sh/uv

# Crear e instalar el entorno virtual
uv venv
uv pip install -e .
```

### Opci√≥n 2: Usando pip tradicional

```bash
# Clonar el repositorio
git clone <url-del-repositorio>
cd ProyectoCienciaDatos

# Crear entorno virtual
python -m venv .venv

# Activar entorno virtual
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt  # o desde pyproject.toml
```

## Uso

### 1. Exploraci√≥n de Datos (EDA)

Ejecutar los notebooks de exploraci√≥n para entender los datos:

```bash
jupyter notebook src/data_exploration/eda.ipynb
```

### 2. Preprocesamiento y Modelado

Ejecutar el notebook principal para entrenar modelos:

```bash
jupyter notebook src/preprocessing_modeling/preprocessing_and_models.ipynb
```

Este notebook incluye:
- Carga de datos originales limpios
- Generaci√≥n de datos sint√©ticos con introducci√≥n controlada de errores
- Preprocesamiento robusto aplicado a datos con ruido
- Manejo de valores faltantes, inconsistencias de tipo y valores at√≠picos
- Entrenamiento de modelos con ambos conjuntos de datos
- Evaluaci√≥n y comparaci√≥n de rendimiento

### 3. Aplicaci√≥n Web Interactiva

Desplegar la aplicaci√≥n Streamlit para hacer predicciones:

```bash
streamlit run reports/app.py
```

La aplicaci√≥n se abrir√° autom√°ticamente en tu navegador (por defecto `http://localhost:8501`).

#### Uso de la App

1. Ingresa los datos cl√≠nicos del paciente en los campos correspondientes
2. Haz clic en "Predecir Riesgo"
3. Revisa el resultado y la probabilidad calculada
4. Consulta las recomendaciones generadas

### 4. Usar Modelos Guardados

```python
import joblib
import pandas as pd

# Cargar modelo
model = joblib.load('models/trained/heart_failure_clinical_records-random-forest.joblib')

# Preparar datos de entrada
data = {
    'age': 75,
    'anaemia': 1,
    'creatinine_phosphokinase': 582,
    'diabetes': 0,
    'ejection_fraction': 20,
    'high_blood_pressure': 1,
    'platelets': 265000.0,
    'serum_creatinine': 1.9,
    'serum_sodium': 130,
    'sex': 0,
    'smoking': 0,
    'time': 7
}

# Hacer predicci√≥n
df = pd.DataFrame([data])
prediction = model.predict(df)
probability = model.predict_proba(df)

print(f"Predicci√≥n: {'Alto Riesgo' if prediction[0] else 'Bajo Riesgo'}")
print(f"Probabilidad de evento fatal: {probability[0][1]:.2%}")
```

## ü§ñ Modelos Implementados

### 1. Regresi√≥n Log√≠stica
- **Ventajas**: Interpretabilidad, r√°pido entrenamiento, probabilidades calibradas
- **Uso**: Baseline y casos donde la interpretabilidad es cr√≠tica

### 2. Random Forest
- **Ventajas**: Alta precisi√≥n, manejo autom√°tico de no linealidades, importancia de variables
- **Uso**: Modelo principal para predicciones optimizadas

## üìà Resultados

### Variables M√°s Importantes
Basado en el an√°lisis de correlaci√≥n y importancia de caracter√≠sticas:

1. **serum_creatinine** (correlaci√≥n ‚âà +0.27) - Mayor nivel asociado a mayor riesgo
2. **age** (correlaci√≥n ‚âà +0.22) - Mayor edad implica mayor riesgo
3. **ejection_fraction** (correlaci√≥n ‚âà -0.21) - Menor fracci√≥n de eyecci√≥n aumenta el riesgo
4. **serum_sodium** (correlaci√≥n ‚âà -0.12) - Niveles bajos aumentan el riesgo

### Hallazgos Cl√≠nicos

- **Edad**: Los grupos de mayor edad (71-95 a√±os) muestran tasas de mortalidad significativamente m√°s altas
- **Anemia**: Pacientes con anemia presentan mayor proporci√≥n de eventos fatales
- **Tabaquismo**: Claramente asociado con mayor mortalidad
- **Diabetes e Hipertensi√≥n**: Factores de riesgo moderados
- **Sexo**: Mayor n√∫mero absoluto de muertes en hombres, principalmente debido al mayor tama√±o de la muestra

## üë• Autores

**Presentado por:**

- Ang√©lica √ìrtiz √Ålvarez (`aortiz016@soyudemedellin.edu.co`)
- Jhon Jader D√≠az G√≥mez (`jdiaz510@soyudemedellin.edu.co`)
- Cristian Camilo Ospina Metaute (`cospina149@soyudemedellin.edu.co`)

---

### **Proyecto de Ciencia de Datos**

**An√°lisis del Dataset de Insuficiencia Card√≠aca**  
`heart_failure_clinical_records_dataset.csv` de Kaggle / UCI Irvine



